---
title: "groupFormation"
author: "Clara Lavrador"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Model Overview

### Purpose


### Agents

Each agent will have a set of three traits and three preferences, which are randomly assigned from 0-100. 
They will also have a number of pursuits they can make per regrouping period.


### Life Cycle

1. Gather info
2. Pursue agents
3. Regroup

#### Gather info

Each agent will calculate three scores with respect to other agents: alliance value, reciprocity score, and overlap score.

The alliance value is calculated by taking the euclidean distance of the agent's preferences with the other agents' traits. 

The reciprocity score is the proportion of pursuits between the agent and each other agent that are reciprocated.

The overlap score is a measurement of pursuit similarity (both sent and received) between the agent and each other agent, with respect to third parties.
  It is based on David Pietraszewski's triadic primitives, whereby:
   
     alliance is the correlation between the agent and each other agents' sent pursuits (i.e., how much they pursue the same agents)
     
     generalization is the correlation between the agent and each other agents' received pursuits (i.e., how much they are pursued by the same agents)
     
     displacement is the correlation between the agent's sent pursuits and each other agents' received pursuits (i.e., how much the agents that agent b pursues pursue agent a)
     
     defense is the correlation between the agent's received and each other agents' sent pursuits (i.e., how much the agents that agent a is pursued by are pursued by agent b)

  
These three scores are then formulated to produce a single pursuit score:

  pursuit value = alliance value + (reciprocity score + overlap score)


#### Pursue agents

Each agent will pursue the agents with the highest pursuit values. 

Sent and received pursuits will be accumulated (and thus used to calculate overlap in the next reassessment period) 

#### Regroup

Agents who have reciprocated pursuits with each other will be considered "grouped" together for that reassessment period.

Then it all begins anew until the max number of reassessment periods has been reached.


### Analysis

For now I'm plotting the number of reciprocated edges over time across all model loops.
But I must think of a better representation... number of groups only tells half the story (bc they still differ in size)

Best thing would be to see if the model loops converge in some other aspect(s)

Also I could compare it to a model that does not include overlap score



## Model

### Packages 
```{r packages}

library(ggplot2)
library(igraph)
library(network)
library(networkDynamic)
library(intergraph)
library(ndtv)
library(dplyr)
library(doParallel)

```


### Parameters
```{r parameters}

#number of agents to generate
popSize <- 160

#pursuitRange <- c(1:5)

#number of pursuits each agent will have for each reassessment period
pursuitAmount <- 3

#number of times agents will reevaluate their pursuits
reassessments <- 250

#number of loops for the whole model
modelLoops <- 20

#number of generations
generations <- 300

#list the four primitives...
all_primitives <- c("alliance", "displacement", "defense", "generalization")

#make list of all possible combinations of the prims
all_combos <- unlist(
  lapply(1:length(all_primitives), function(k) {
    combn(all_primitives, k, simplify = FALSE)
  }),
  recursive = FALSE
)

#add the null option
all_combos <- c(all_combos, "XX")

#list the prim combo abbreviations in order to append later
prim_abbrev <- c("A",
"P",
"D",
"G",
"AP",
"AD",
"AG",
"PD",
"PG",
"DG",
"APD",
"APG",
"ADG",
"PDG",
"APDG",
"XX"
) ##should I include NULL strategy?

primies <- data.frame("prim_abbrev" = prim_abbrev, 
                      "prim_list" = I(all_combos))


primiesSampling <- rep(prim_abbrev, each = 10) #temporary, for 150 agents

selStrength <- 0.15

#primies$prop <- 0.0625


#proportion of strats





```


### Functions
```{r functions}
#Agent Generate Function#

agentGenerate <- function(n){
  
  #randomly generate 3 traits and their corresponding preferences for each agent

  alliance <- abs(rnorm(popSize, mean = 50, sd = 10))
  
  alliance <- round(alliance, digits = 0)
  
  alliance <- (alliance/100)
  
  #ID <- 1:n
  
  strat <- sample(primiesSampling, n, replace = F)
  
  #put it all together in a df
  agents <- data.frame(alliance, strat)
  
  #add the actual list of primitives to agent's row to be referenced in life cycle
  agents$stratList <- primies$prim_list[match(agents$strat, primies$prim_abbrev)]
  
  return(agents)
  
}


weighted_jaccard <- function(x, y) {
  
  # Calculate the numerator: Sum of minimum intensities
  numerator <- sum(pmin(x, y))
  
  # Calculate the denominator: Sum of maximum intensities
  denominator <- sum(pmax(x, y))
  
  # Handle edge case where denominator is 0 (all zeros)
  if (denominator == 0) return(0)
  
  # Calculate weighted Jaccard similarity
  similarity <- numerator / denominator
  return(similarity)
}


#New Overlap Function#
#each agent will calculate their alliance, gen, displacement, and defense overlap between themselves and every other agent
#this vector will be stored in the row 

#fold triangles for alliance and gen, transpose for displacement to defense

#output = 4 matrices

overlap_prims <- function(adjMat){
  
  #Make empty matrices to store overlap for each prim
  
  allianceMat <- matrix(data = 0, nrow = popSize, ncol = popSize)
  generalizationMat <- matrix(data = 0, nrow = popSize, ncol = popSize)
  defenseMat <- matrix(data = 0, nrow = popSize, ncol = popSize)
  displacementMat <- matrix(data = 0, nrow = popSize, ncol = popSize)
  
  #loop through each agent
  
  for(agent in 1:popSize){
    
    #Alliance#
    #calculate correlation of agent's row with other agents' rows 
    
      alliance = sapply(1:nrow(adjMat), function(i) {
        
        #only compute for agents that proceed main agent numerically to prevent a redundant calculation
        if (i <= agent) 
          return(NA)
        
        #when comparing the two vectors, ignore the two cells belonging to each agent (only third party relationships matter here)
        exclude_indices <- c(agent, i)
        x_filtered <- adjMat[i,-exclude_indices]
        agent_row_filtered <- adjMat[agent,-exclude_indices]
        
        #calculate the similarity
        weighted_jaccard(x_filtered, agent_row_filtered)
      })
      
      #Add agent's score vector to their row in the overlap matrix corresponding to prim
      allianceMat[agent,] <- alliance
      
      
    #Generalization#
    #calculate correlation of agent's column with other agents' columns
      
      generalization = sapply(1:ncol(adjMat), function(j) {
        
        #only compute for agents that proceed main agent numerically to prevent a redundant calculation
        if (j <= agent)
          return(NA)
        
        #when comparing the two vectors, ignore the two cells belonging to each agent (only third party relationships matter here)
        exclude_indices <- c(agent, j)
        x_filtered <- adjMat[-exclude_indices, j]
        agent_filtered <- adjMat[-exclude_indices, agent]
        weighted_jaccard(x_filtered, agent_filtered)
      })
      
      #Add agent's score vector to their row in the overlap matrix corresponding to prim
      generalizationMat[agent,] <- generalization
    
      
    #Displacement#
    #calculate correlation of agent's row with other agents' columns
      
      displacement = sapply(1:nrow(adjMat), function(j) { #do all not some bc then we'll do inverse for displacement
        
        #avoid computing between self
        if (j == agent)
          return(NA)
        
        #when comparing the two vectors, ignore the two cells belonging to each agent (only third party relationships matter here)
        exclude_indices <- c(agent, j)
        x_filtered <- adjMat[-exclude_indices, j]
        agent_filtered <- adjMat[agent,-exclude_indices]
        weighted_jaccard(x_filtered, agent_filtered)
      })
      
      #Add agent's score vector to their row in the overlap matrix corresponding to prim
      displacementMat[agent,] <- displacement
    
  }
  
  #Completing the matrices
  
  #Transpose the alliance matrix on itself since value for [i,j] = value for [j,i]
  allianceMat[lower.tri(allianceMat)] <- t(allianceMat)[lower.tri(allianceMat)]
  
  #Transpose the generalization matrix on itself since value for [i,j] = value for [j,i]
  generalizationMat[lower.tri(generalizationMat)] <- t(generalizationMat)[lower.tri(generalizationMat)]
  
  #Transpose the displacement matrix to create defense mat since displacement value for [i,j] = defense value for [j,i]
  
  defenseMat <- t(displacementMat)
  
  return(list(alliance = allianceMat, generalization = generalizationMat, displacement = displacementMat, defense = defenseMat))
  
}

#Overlap Score Calculation#
#average based on agent's prim strat

overlap_mean <- function(agent, agentsDF, matrixList){
  
  if (agentsDF$strat[agent] == "XX") {
    
    #if the agent is using the null strategy, return overlap scores of 1
    means <- rep(1, popSize)
    
    #but for everyone else:
  } else {
    
    #get the agent's prims from the agent DF
    prims <- agentsDF$stratList[agent]
    prims <- unlist(prims)
    
    #use only the matrices included in their prim combo
    subsetMats <- matrixList[prims]
    
    #get the agent's rows from the prim mats
    row_values <-
      do.call(rbind, lapply(subsetMats, function(mat)
        mat[agent,]))
    
    #take the element wise average
    means <- colMeans(row_values)
    
  }
  
  return(means)
  
} 


#Reciprocity Function#

reciprocity <- function(agent, adjMat){
  
  #pull agent's column which represents their received pursuits
  received <- adjMat[,agent]
  
  #pull agent's row which represents their sent pursuits
  sent <- adjMat[agent,]
    
  #calculate proportions of pursuits which were received
  reciprocity_scores <- (received / (received + sent))
  
  #nullify their own reciprocity score
  reciprocity_scores[agent] <- NA
  
  return(reciprocity_scores)
  
}


#Contributions#
#

payoff <- function(gameMatrix, agentDF, payoffs){
  
  #start the sum
  contributionTot <- 0
  
  #pull the row names to loop though
  groupIDs <- rownames(gameMatrix)
  
  #for each agent...
  for(agent in groupIDs){
    
    #their max contribution is their alliance value
    maxContribution <- agentDF$alliance[row.names(agentDF) == agent] * 100
    
    #get the percent of the AV they will contribute, which is proportional to number of recip ties within group
    proportionTied <- sum(gameMatrix[as.character(agent), ])/(nrow(gameMatrix)-1)
    
    #calculate their contribution 
    contribution <- maxContribution * proportionTied
    
    #add their total contribution to those of the other agents
    contributionTot <- contributionTot + contribution
    
    #add their noncontributed pay to their corresponding slot in payoff vector (what they keep)
    payoffs[as.numeric(agent)] <- payoffs[as.numeric(agent)] + (maxContribution - contribution)
    
  }
  
  contributionTot <- contributionTot * 1.2
  
  #divide the pooled contributions by the number of agents in the group
  basePay <- contributionTot/nrow(gameMatrix)
  
  payoffs[as.numeric(gamerGroup)] <- payoffs[as.numeric(gamerGroup)] + basePay
  
  #return the single payoff
  return(payoffs)
  
}



#fitness <- runif(100, min = 0, max = 1)


reproduce <- function(agentDF, payoffVector, selStrength, n){
  
  #rescale payoffs to be between 0-1
  pay <- payoffVector - min(payoffVector)
  pay <- pay/max(pay)
  
  #add constant to prob weight to fix strength of selection
  pay <- pay + (1/selStrength) #the bigger the decimal, the larger the diff in probability
  
  #link payout to corresponding agent
  agentDF$pay <- pay
  
  #generate random offspring
  offspringDF <- agentDF[sample(1:nrow(agentDF), n, replace = T, prob = pay),] #the bigger the decimal, the larger the diff
  
  #Reset IDs
  row.names(offspringDF) <- 1:n
  
  return(offspringDF)
  
}
```


#Parallel Processing#

```{r parallel}

startTime <- Sys.time()

agentDFs <- lapply(1:modelLoops, function(x) agentGenerate(popSize))

results <- data.frame()

numCores <- detectCores()
cl <- makeCluster(numCores - 3)
cl <- makeCluster(cl)

registerDoParallel(cl)

results <- foreach(m = 1:length(agentDFs), .combine = rbind) %dopar% {
  
  #set generation to 1
  g <- 1
  
  #generate the starting agents
  agents <- agentDFs[[m]]
  
  generation_results <- list()
  
  while(g <= generations){
    
    print(paste("Model",m,"Generation", g)) #for keeping track
    
    #generate adjacency matrix (populate with 1)
    pursuitMatrix <- matrix(1, nrow = popSize, ncol = popSize)
    
    #store each reassessment period's cumulative adjacency matrix so that agents can reference the previous one when calculating their overlap/reciprocal scores
    pursuitMatrix_list <- list(pursuitMatrix)
    
    #initialize list to store each reassessment's adjacency matrix as binary for that iteration so we can look at who was reciprocal at each reassessment period
    tiesMatrix_list <- list(length = reassessments)
    
    
    #for each reassessment... (agents look backwards so start from 2)
    for (t in 2:reassessments) {
      
      #create the empty noncumulative adjacency matrix
      tiesMatrix <- matrix(0, nrow = popSize, ncol = popSize)
      
      #Calculate overlap in previous adjacency matrix#
      
      #make empty matrix list
      overlap_matrices <- overlap_prims(pursuitMatrix_list[[t-1]])
      
      
      #for each agent...
      for (a in 1:nrow(agents)) {
        
        #calculate overlap scores between themselves and the other agents
        overlap_scores <- overlap_mean(a, agents, overlap_matrices)
        
        #calculate the reciprocity scores between themselves and the other agents
        reciprocity_scores <- reciprocity(a, pursuitMatrix_list[[t - 1]])
        
        #calculate the alliance values
        alliance_values <- agents$alliance
        
        #Combine overlap, reciprocity, and alliance scores into single calculation
        pursuit_scores <-overlap_scores * reciprocity_scores * alliance_values
        
        #sort by product in descending order and get the indices of the top value agents
        pursuit_indices <- order(-pursuit_scores)[1:pursuitAmount]
        
        #add 1 to their pursuits in the cumulative the adjacency matrix
        pursuitMatrix[a, pursuit_indices] <- pursuitMatrix[a, pursuit_indices] + 1
        
        #and to the individual one
        tiesMatrix[a, pursuit_indices] <- 1
        
        
      }
      
      #add the pursuitMatrix to the matrix list
      pursuitMatrix_list[[t]] <- pursuitMatrix
      
      #add the non cumulative matrix to its list
      tiesMatrix_list[[t]] <- tiesMatrix
      
    }
    
    #Game#
    
    #create empty payoff vector to store payoffs (later used for reproduction)
    payoffs <- vector(mode = "numeric", length = popSize)
    
    for(gamer in 1:popSize){
      
      #pull indices of agents' reciprocated ties
      gamerGroup <- which(tiesMatrix[gamer, ] == 1)
      
      #add the gamer to the group indices
      gamerGroup <- c(gamerGroup, gamer)
      
      #subset the ties matrix to include only those in group
      gamersMat <- tiesMatrix[gamerGroup, gamerGroup, drop = F]
      
      #change the names back to original indices
      rownames(gamersMat) <- gamerGroup
      colnames(gamersMat) <- gamerGroup
      
      #calculate the payoff each agent will receive
      payoffs <- payoff(gamersMat, agents, payoffs)
      
    }
    
    #Reproduce#
    #agents reproduce
    agents <- reproduce(agents, payoffs, selStrength, popSize)
    
    #change alliance values to be within SD of parent
    # for (a in 1:nrow(agents)) {
    #   
    #   agents$alliance[a] <- rnorm(1, mean = agents$alliance[a], sd = .10)
    #   
    # }
    
    #get the breakdown of strat population
    stratTable <- as.data.frame(table(agents$strat))
    stratTable$loop <- m
    stratTable$generation <- g
    
    generation_results[[g]] <- stratTable

    if (max(stratTable$Freq, na.rm = T) == popSize) {
      break  # Exit the loop early if condition is met
    }
    
    g <- g+1
    
  }
  
  do.call(rbind, generation_results)
  
}

stopCluster(cl)

endTime <- Sys.time()

print(endTime - startTime)

#drive_upload(results, path = "groupFormationResults/resultsParallel.csv", overwrite = TRUE)



```

















### Life Cycle

```{r lifeCycle}

start.time <- Sys.time()

results <- data.frame("loop" = rep(1:modelLoops, each = length(all_combos)*(generations+1)),
                      "generation" = rep(0:generations, each = length(all_combos)),
                      "combo" = rep(prim_abbrev),
                      "population" = NA)

# resultsbind <- data.frame("generation" = rep(151:200, each = length(all_combos)),
#                       "combo" = rep(prim_abbrev),
#                       "population" = NA)
# 
# results <- rbind(results, resultsbind)
# 
  results$population[results$generation == 0] <- 10
# 
# names(results)[names(results) == 'amount'] <- 'population'


for(m in 1:modelLoops) {
  
  print(m)
  
  #Generate parent agents
  agents <- agentGenerate(popSize)
  
  final_tiesMatrices <- list(length = generations)
  
  lastGraphs <- list(length = generations)
  
  payoff_list <- list(length = generations)
  
  g <- 1
  
  while(g <= generations){
    
    print(g) #for keeping track
  
    #generate adjacency matrix (populate with 1)
    pursuitMatrix <- matrix(1, nrow = popSize, ncol = popSize)
    
    #store each reassessment period's cumulative adjacency matrix so that agents can reference the previous one when calculating their overlap/reciprocal scores
    pursuitMatrix_list <- list(pursuitMatrix)
    
    #initialize list to store each reassessment's adjacency matrix as binary for that iteration so we can look at who was reciprocal at each reassessment period
    tiesMatrix_list <- list(length = reassessments)
    
    
    #for each reassessment... (agents look backwards so start from 2)
    for (t in 2:reassessments) {
      
      #create the empty noncumulative adjacency matrix
      tiesMatrix <- matrix(0, nrow = popSize, ncol = popSize)
    
      #Calculate overlap in previous adjacency matrix#
      
      #make empty matrix list
      overlap_matrices <- overlap_prims(pursuitMatrix_list[[t-1]])
      
      
      #for each agent...
      for (a in 1:nrow(agents)) {
        
        #calculate overlap scores between themselves and the other agents
        overlap_scores <- overlap_mean(a, agents, overlap_matrices)
        
        #calculate the reciprocity scores between themselves and the other agents
        reciprocity_scores <- reciprocity(a, pursuitMatrix_list[[t - 1]])
        
        #calculate the alliance values
        alliance_values <- agents$alliance
        
        #Combine overlap, reciprocity, and alliance scores into single calculation
        pursuit_scores <-overlap_scores * reciprocity_scores * alliance_values
        
        #sort by product in descending order and get the indices of the top value agents
        pursuit_indices <- order(-pursuit_scores)[1:pursuitAmount]
        
        #add 1 to their pursuits in the cumulative the adjacency matrix
        pursuitMatrix[a, pursuit_indices] <- pursuitMatrix[a, pursuit_indices] + 1
        
        #and to the individual one
        tiesMatrix[a, pursuit_indices] <- 1
        
        
      }
      
      #add the pursuitMatrix to the matrix list
      pursuitMatrix_list[[t]] <- pursuitMatrix
      
      #add the non cumulative matrix to its list
      tiesMatrix_list[[t]] <- tiesMatrix
    
    }
    
    #Game#
      
    #create empty payoff vector to store payoffs (later used for reproduction)
    payoffs <- vector(mode = "numeric", length = popSize)
    
    for(gamer in 1:popSize){
      
      #pull indices of agents' reciprocated ties
      gamerGroup <- which(tiesMatrix[gamer, ] == 1)
      
      #add the gamer to the group indices
      gamerGroup <- c(gamerGroup, gamer)
      
      #subset the ties matrix to include only those in group
      gamersMat <- tiesMatrix[gamerGroup, gamerGroup, drop = F]
      
      #change the names back to original indices
      rownames(gamersMat) <- gamerGroup
      colnames(gamersMat) <- gamerGroup
      
      #calculate the payoff each agent will receive
      pay <- payoff(gamersMat, agents)
      
      
      
    }
    
    
    payoff_list[[g]] <- payoffs
      
    #Reproduce#
    
    igraph <- graph_from_adjacency_matrix(tiesMatrix)
   
    V(igraph)$alliance <- agents$alliance
  
    V(igraph)$strat <- agents$strat
  
    lastGraphs[[g]] <- igraph
    
    
    #agents reproduce
    agents <- reproduce(agents, payoffs, selStrength, popSize)
    
    #change alliance values to be within SD of parent
    # for (a in 1:nrow(agents)) {
    #   
    #   agents$alliance[a] <- rnorm(1, mean = agents$alliance[a], sd = .10)
    #   
    # }
    
    final_tiesMatrices[[g]] <- tiesMatrix
    
    
    #get the breakdown of strat population
    stratTable <- as.data.frame(table(agents$strat))
    
    #add the amounts to the results df
    results$population[results$generation == g & results$loop == m] <- stratTable$Freq[match(results$combo, stratTable$Var1)]
      
    print(stratTable)
    
    if (max(results$population, na.rm = T) == popSize) {
      break  # Exit the loop early if condition is met
    }
    
    g <- g+1
    
  }
  
}
  

#remember that ties mat has all pursuits, not just reciprocal



end.time <- Sys.time()

print(end.time - start.time)




      
```

### Analysis

```{r analysis}

#do bar graph with generations on x, phenotype on y, and goes to max generation with at least 1 offspring of that phenotype

results_labs <- results %>%
  group_by(Var1) %>%
  filter(generation == max(generation)) %>%
  ungroup()

#results <- results[results$generation < 141,]

p1 <- ggplot(data = results[results$loop == 1,],
               aes(x = generation,
                   y = Freq,
                   color = Var1)) +
  labs(x = "Generation",
       y = "Population",
       color = "Phenotype") +
  geom_line() +
  geom_text(
    data = results_labs,
    aes(label = Var1),
    hjust = -0.1,
    size = 4,
    fontface = "bold"
  ) +
  xlim(min(results$generation), max(results$generation) + 0.5) +  # Give space for labels
  theme_minimal()



plot(p1)




#calculate percent of edges that are present in previous reassessment period
results$percentPersist <- (results$intersectLast/results$numEdges)*100


lastGraphsFull <- lastGraphs

#only include edges that are reciprocated
for(g in 1:length(lastGraphs)) {
  lastGraphs[[g]] <- subgraph.edges(lastGraphs[[g]],
                                    E(lastGraphs[[g]])[which_mutual(lastGraphs[[g]])],
                                    delete.vertices = F) #maybe i can just do this with true to get groups
  
}



plot(lastGraphs[[2]],
     layout = layout.fruchterman.reingold,
     #vertex.label = NA,
     #  rescale = F,
     layout = layout_with_kk,
     vertex.size = 8,
     #vertex.color = vertex.color,
     vertex.label.color = "black",
     vertex.shape = "circle",
     edge.arrow.size = 0.3)






#Plots

#Edge Amount Plot#
#plot the number of reciprocated edges throughout reassessment periods [average this across loops w SE]

persist_plot <- ggplot(data = resultsTail,
       aes(x = reassess,
           y = numEdges,
           color = as.factor(loop),
           groups = as.factor(loop)
       )) +
  facet_wrap(~prims) +
  labs(title = "Percent of Edges that Persist from Previous Reassessment Period",
       subtitle = "last 100 reassessments across model loops for each primitive combo",
       x = "reassessment period",
       y = "percent persist",
       color = "loop") +
  geom_smooth(se = F) +
  geom_hline(yintercept = 300, linetype = "dashed")

print(persist_plot)



#Edge Persistence Plot#
#plot the percent of edges that persist for each combo across model loops
persist_plot <- ggplot(data = results,
       aes(x = reassess,
           y = percentPersist,
           color = as.factor(loop),
           groups = as.factor(loop)
       )) +
  facet_wrap(~prims) +
  labs(title = "Percent of Edges that Persist from Previous Reassessment Period",
       subtitle = "last 100 reassessments across model loops for each primitive combo",
       x = "reassessment period",
       y = "percent persist",
       color = "loop") +
  geom_smooth(se = F) +
  geom_hline(yintercept = 100, linetype = "dashed")

print(persist_plot)



#Ranks

#subset results df to only tail entries (after model converges)
resultsTail <- results[results$reassess > reassessments - 100,]

#calculate mean edge persistence, alliance val assortativity, and number of isolates 

edgesTail <- resultsTail %>%
  group_by(prims) %>%
  summarize(
    meanEdges = mean(numEdges, na.rm = TRUE),
    sdEdges = sd(numEdges, na.rm = TRUE),
    .groups = "drop"
  )

persistTail <- resultsTail %>%
  group_by(prims) %>%
  summarize(
    meanPersist = mean(percentPersist, na.rm = TRUE),
    sdPersist = sd(percentPersist, na.rm = TRUE),
    .groups = "drop"
  )

assortTail <- resultsTail %>%
  group_by(prims) %>%
  summarize(
    meanAssort = mean(assort_alliance, na.rm = TRUE),
    sdAssort = sd(assort_alliance, na.rm = TRUE),
    .groups = "drop"
  )

isolatesTail <- resultsTail %>%
  group_by(prims) %>%
  summarize(
    meanIsolates = sum(num_isolates, na.rm = TRUE),
#    sdIsolates = sd(num_isolates, na.rm = TRUE),
    .groups = "drop"
  )


###########################################


#create vector of unique alliance values in order 
allianceVals <- sort(unique(agents$alliance))

#create color ramp palette
cols <- setNames(colorRampPalette(c("red", "yellow", "green"))(length(allianceVals)), allianceVals)

# initialize color vector
vertColors <- rep(NA, popSize)

# assign colors based on alliance values
for (i in 1:nrow(agents)) {
  
  a <- agents$alliance[i]
  
  agents$color[i] <- cols[as.character(a)]
}

###

# Generate 15 distinct colors
color_palette <- distinctColorPalette(15) 

# Map colors to categories
category_colors <- setNames(color_palette, unique(agents$strat)) 

# Assign colors based on category
agents$stratColor <- category_colors[agents$strat]

###


#add vertex attributes
for(r in 1:length(igraph_list)) {
  
  V(igraph_list[[r]])$name <- c(1:150)
  
  V(igraph_list[[r]])$alliance <- agents$alliance
  
  V(igraph_list[[r]])$strat <- agents$strat
  
  V(igraph_list[[r]])$color <- agents$stratColor
  
}


plot(lastGraphs[[10]],
     layout = layout.fruchterman.reingold,
     #vertex.label = NA,
     #  rescale = F,
     layout = layout_with_kk,
     vertex.size = 8,
     #vertex.color = vertex.color,
     vertex.label.color = "black",
     vertex.shape = "circle",
     edge.arrow.size = 0.3)


legend("topright", legend = names(category_colors), fill = category_colors, title = "Categories", border = "black", cex = 0.8, bty = "n")


# ggplot(data = results,
#        aes(x = reassess,
#            y = numEdges,
#            color = as.factor(prims))) +
#   labs(title = "",
#        subtitle = "",
#        x = "reassessment period",
#        y = "percent of edges that are reciprocated",
#        color = "primitives") +
#   geom_smooth(se= F)



overlap(50, adjMat = random_matrix, component = c("alliance"))


random_matrix <- matrix(sample(0:1, 400, replace = T), nrow = 20, ncol = 20)
gameMatrix <- matrix(sample(0:1, 16, replace = T), nrow = 4, ncol = 4)

```

















